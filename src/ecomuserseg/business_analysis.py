import pandas as pd
import numpy as np

def analyze_cluster(cluster_id, data_clustered, cluster_col='cluster'):
    """
    Analyse d√©taill√©e d'un cluster sp√©cifique
    
    Parameters
    ----------
    cluster_id : int
        ID du cluster √† analyser
    data_clustered : pd.DataFrame
        DataFrame avec les donn√©es et les clusters
    cluster_col : str
        Nom de la colonne contenant les clusters
    """
    cluster_data = data_clustered[data_clustered[cluster_col] == cluster_id]
    total_customers = len(data_clustered)
    cluster_size = len(cluster_data)
    
    print(f"\n{'='*50}")
    print(f"CLUSTER {cluster_id}")
    print(f"{'='*50}")
    print(f"Taille: {cluster_size} clients ({cluster_size/total_customers*100:.1f}% du total)")
    
    # Statistiques principales
    print(f"\nCARACT√âRISTIQUES PRINCIPALES:")
    
    # Variables √† analyser 
    variables_to_analyze = {
        'total_spend': 'D√©pense totale moyenne',
        'nb_orders': 'Nombre moyen de commandes',
        'mean_review_score': 'Note moyenne',
        'mean_delivery_days': 'D√©lai de livraison moyen',
        'haversine_distance': 'Distance moyenne au si√®ge',
        'customer_state': '√âtat principal',
        'favorite_sale_month': 'Mois d\'achat pr√©f√©r√©'
    }
    
    for var, description in variables_to_analyze.items():
        if var in cluster_data.columns:
            if var in ['customer_state', 'favorite_sale_month']:
                # Variables cat√©gorielles
                mode_val = cluster_data[var].mode()
                if not mode_val.empty:
                    print(f"- {description}: {mode_val.iloc[0]}")
            else:
                # Variables num√©riques
                mean_val = cluster_data[var].mean()
                if var == 'mean_review_score':
                    print(f"- {description}: {mean_val:.2f}/5")
                elif var in ['total_spend']:
                    print(f"- {description}: {mean_val:.2f} BRL")
                elif var in ['mean_delivery_days', 'haversine_distance']:
                    unit = 'jours' if 'days' in var else 'km'
                    print(f"- {description}: {mean_val:.1f} {unit}")
                else:
                    print(f"- {description}: {mean_val:.1f}")

def create_business_interpretation(data_clustered, cluster_col='cluster'):
    """
    Cr√©e une interpr√©tation m√©tier des clusters
    
    Parameters
    ----------
    data_clustered : pd.DataFrame
        DataFrame avec les donn√©es et les clusters
    cluster_col : str
        Nom de la colonne contenant les clusters
    
    Returns
    -------
    dict
        Dictionnaire avec l'interpr√©tation m√©tier de chaque cluster
    """
    interpretations = {}
    
    # Calcul des m√©dianes et moyennes globales pour comparaison
    global_stats = {}
    if 'total_spend' in data_clustered.columns:
        global_stats['spend_median'] = data_clustered['total_spend'].median()
        global_stats['spend_mean'] = data_clustered['total_spend'].mean()
    if 'nb_orders' in data_clustered.columns:
        global_stats['orders_median'] = data_clustered['nb_orders'].median()
    if 'mean_review_score' in data_clustered.columns:
        global_stats['rating_median'] = data_clustered['mean_review_score'].median()
    if 'mean_delivery_days' in data_clustered.columns:
        global_stats['delivery_median'] = data_clustered['mean_delivery_days'].median()
    if 'haversine_distance' in data_clustered.columns:
        global_stats['distance_median'] = data_clustered['haversine_distance'].median()
    
    # Collecte des moyennes par cluster pour comparaison relative
    cluster_stats = {}
    for cluster_id in sorted(data_clustered[cluster_col].unique()):
        cluster_data = data_clustered[data_clustered[cluster_col] == cluster_id]
        cluster_stats[cluster_id] = {
            'spend': cluster_data['total_spend'].mean() if 'total_spend' in cluster_data.columns else 0,
            'rating': cluster_data['mean_review_score'].mean() if 'mean_review_score' in cluster_data.columns else 0,
            'delivery': cluster_data['mean_delivery_days'].mean() if 'mean_delivery_days' in cluster_data.columns else 0,
            'distance': cluster_data['haversine_distance'].mean() if 'haversine_distance' in cluster_data.columns else 0
        }
    
    # Tri des clusters par d√©pense pour hi√©rarchisation
    clusters_by_spend = sorted(cluster_stats.items(), key=lambda x: x[1]['spend'], reverse=True)
    
    for cluster_id in sorted(data_clustered[cluster_col].unique()):
        cluster_data = data_clustered[data_clustered[cluster_col] == cluster_id]
        
        # Caract√©ristiques moyennes
        cluster_size = len(cluster_data)
        
        # Variables pour l'interpr√©tation
        avg_spend = cluster_stats[cluster_id]['spend']
        avg_orders = cluster_data['nb_orders'].mean() if 'nb_orders' in cluster_data.columns else 0
        avg_rating = cluster_stats[cluster_id]['rating']
        avg_delivery = cluster_stats[cluster_id]['delivery']
        avg_distance = cluster_stats[cluster_id]['distance']
        
        value_type = "Clients Standards"  # par d√©faut
        
        # 1. D'abord identifier les clients √† probl√®me (priorit√© absolue)
        if avg_rating < 2.5:  # Tr√®s insatisfaits
            if avg_delivery > global_stats.get('delivery_median', 10) * 1.8:
                value_type = "Clients √† Risque - Livraison"
            else:
                value_type = "Clients Insatisfaits"
        
        # 2. Puis classifier selon performance combin√©e (satisfaction + d√©pense + livraison)
        elif avg_rating >= 4.5 and avg_delivery <= global_stats.get('delivery_median', 10):
            # Tr√®s satisfaits ET livraison rapide
            spend_rank = [i for i, (cid, _) in enumerate(clusters_by_spend) if cid == cluster_id][0]
            if spend_rank == 0:  # Plus gros d√©pensier
                value_type = "Clients VIP Premium"
            elif avg_spend > global_stats.get('spend_mean', 100):
                value_type = "Clients VIP"
            else:
                value_type = "Clients Satisfaits"
        
        # 3. Clients avec livraison probl√©matique mais toujours satisfaits
        elif avg_delivery > global_stats.get('delivery_median', 10) * 1.4:
            if avg_distance > global_stats.get('distance_median', 500) * 1.3:
                value_type = "Clients √âloign√©s"
            elif avg_rating >= 4.0:  # Satisfaits malgr√© les d√©lais
                value_type = "Clients Tol√©rants"
            else:
                value_type = "Clients Livraison Lente"
        
        # 4. Classification par niveau de d√©pense et engagement
        elif avg_spend > global_stats.get('spend_median', 100) * 1.5:
            if avg_rating >= 4.0:
                spend_rank = [i for i, (cid, _) in enumerate(clusters_by_spend) if cid == cluster_id][0]
                if spend_rank <= 1:  # Top 2 des d√©pensiers
                    value_type = "Clients Premium"
                else:
                    value_type = "Gros Acheteurs"
            else:
                value_type = "Gros Acheteurs Mitig√©s"
        
        # 5. Clients moyens et occasionnels
        elif avg_spend < global_stats.get('spend_median', 100) * 0.9:
            if avg_rating >= 4.5:
                value_type = "Clients Satisfaits √âconomes"
            else:
                value_type = "Clients Occasionnels"
        
        # 6. Reste = clients standards
        else:
            if avg_rating >= 4.2:
                value_type = "Clients R√©guliers Satisfaits"
            else:
                value_type = "Clients Standards"
        
        interpretations[cluster_id] = {
            'nom': value_type,
            'taille': cluster_size,
            'pourcentage': cluster_size / len(data_clustered) * 100,
            'caracteristiques': {
                'depense_moyenne': avg_spend,
                'nb_commandes': avg_orders,
                'satisfaction': avg_rating,
                'delai_livraison': avg_delivery,
                'distance': avg_distance
            }
        }
    
    return interpretations

def print_business_summary(business_interpretation):
    """
    Affiche un r√©sum√© de l'interpr√©tation m√©tier.
    
    Parameters
    ----------
    business_interpretation : dict
        Dictionnaire avec l'interpr√©tation m√©tier
    """
    print("INTERPR√âTATION M√âTIER DES CLUSTERS")
    print("="*60)
    
    for cluster_id, info in business_interpretation.items():
        print(f"\nCLUSTER {cluster_id}: {info['nom']}")
        print(f"   Taille: {info['taille']} clients ({info['pourcentage']:.1f}%)")
        print(f"   D√©pense moyenne: {info['caracteristiques']['depense_moyenne']:.2f} BRL")
        print(f"   Commandes moyennes: {info['caracteristiques']['nb_commandes']:.1f}")
        print(f"   Satisfaction: {info['caracteristiques']['satisfaction']:.2f}/5")
        print(f"   D√©lai livraison: {info['caracteristiques']['delai_livraison']:.1f} jours")
        
        # Ajout d'une recommandation actionnable
        if "Risque" in info['nom'] or "Insatisfaits" in info['nom']:
            print(f"   ‚ö†Ô∏è  ATTENTION: Segment prioritaire pour am√©liorer l'exp√©rience client")
        elif "VIP" in info['nom'] or "Premium" in info['nom']:
            print(f"   ‚≠ê OPPORTUNIT√â: Segment √† valoriser avec des offres premium")
        elif "√âloign√©s" in info['nom']:
            print(f"   üìç ACTION: Optimiser la logistique pour ce segment g√©ographique")

def create_cluster_profiles(data_clustered, numerical_cols, cluster_col='cluster'):
    """
    Cr√©e les profils moyens des clusters.
    
    Parameters
    ----------
    data_clustered : pd.DataFrame
        DataFrame avec les donn√©es et les clusters
    numerical_cols : list
        Liste des colonnes num√©riques √† analyser
    cluster_col : str
        Nom de la colonne contenant les clusters
    
    Returns
    -------
    pd.DataFrame
        Profils moyens des clusters
    """
    return data_clustered.groupby(cluster_col)[numerical_cols].mean()

def save_clustering_results(model, data_clustered, cluster_profiles, business_interpretation, 
                          optimal_k, sil_score, output_dir='../output'):
    """
    Sauvegarde tous les r√©sultats du clustering.
    
    Parameters
    ----------
    model : Pipeline
        Mod√®le de clustering entra√Æn√©
    data_clustered : pd.DataFrame
        Donn√©es avec clusters
    cluster_profiles : pd.DataFrame
        Profils des clusters
    business_interpretation : dict
        Interpr√©tation m√©tier
    optimal_k : int
        Nombre optimal de clusters
    sil_score : float
        Score de silhouette
    output_dir : str
        R√©pertoire de sortie
    """
    import pickle
    import os
    
    # Cr√©er le r√©pertoire s'il n'existe pas
    os.makedirs(output_dir, exist_ok=True)
    
    # Sauvegarde du mod√®le
    with open(f'{output_dir}/kmeans_model.pkl', 'wb') as f:
        pickle.dump(model, f)
    
    # Sauvegarde des donn√©es avec clusters
    data_clustered.to_csv(f'{output_dir}/customers_with_clusters.csv')
    
    # Sauvegarde des profils de clusters
    cluster_profiles.to_csv(f'{output_dir}/cluster_profiles.csv')
    
    # R√©sum√© des r√©sultats
    results_summary = {
        'optimal_k': optimal_k,
        'silhouette_score': sil_score,
        'cluster_sizes': data_clustered['cluster'].value_counts().to_dict(),
        'business_interpretation': business_interpretation
    }
    
    with open(f'{output_dir}/clustering_results.pkl', 'wb') as f:
        pickle.dump(results_summary, f)
    
    print("Mod√®le et r√©sultats sauvegard√©s avec succ√®s!")
    print(f"- Mod√®le K-Means: {optimal_k} clusters")
    print(f"- Score de silhouette: {sil_score:.3f}")
    print(f"- {len(data_clustered)} clients segment√©s")
